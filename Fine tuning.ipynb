{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":36326,"status":"ok","timestamp":1756564216892,"user":{"displayName":"Vishal Jaiswal","userId":"13494830087982063843"},"user_tz":-330},"id":"TZGaUjq354SQ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9b3c90a0-220f-4197-e358-2f59dd668612"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m52.3/52.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m312.9/312.9 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m544.8/544.8 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m196.0/196.0 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m117.2/117.2 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m131.7/131.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m213.6/213.6 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install -q unsloth"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":75383,"status":"ok","timestamp":1756564292268,"user":{"displayName":"Vishal Jaiswal","userId":"13494830087982063843"},"user_tz":-330},"id":"NUaBCvM08GYX","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4cabfe82-46f3-43ba-d34a-b42159112a37"},"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"]}],"source":["from unsloth import FastLanguageModel\n","import torch"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25772,"status":"ok","timestamp":1756564318044,"user":{"displayName":"Vishal Jaiswal","userId":"13494830087982063843"},"user_tz":-330},"id":"0sVhyeiJ_VtY","outputId":"a9bfdc2c-0b09-4750-d3be-93db452cec3a"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install -q --force-reinstall --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281,"referenced_widgets":["f8debbbac99d4c52b010dfa0500ba874","fe3c441eb73b40dfadc9e078ffc28d2e","aad28fbe9fc24853ad98d9954228a372","7d5f9ea80e3440aeac015a3af03092ad","f7007d8b15204904882c4e7f6e353f48","521f4aa6518343809f597a36e1fd23d0","7b0b3ef4e62d4cd8adf035cf36d9b734","02383d6b7a6741a68c5f7e445b31308e","1bff7981c1834c0a8a1f6392b5f62a6e","8b0c78818b1e4e20a7dcc4e277b47297","0aa8103b97a14d40a1f91b6549fc9d93","613ee6146cb24bce831c5bf93ecaa5da","2bfcd192129343f2b47e1f16f052542a","2a983c8a9bab4ca9a12c3a333d478716","7a557c285f8f478fb344e367ecc34f2c","ab899d8966d843dab10f241d9cdffeea","b857b8af2b294f52b717ce116e30dec0","cef84c1d6247454a894255fd6eefd6b2","952f7db6d1f14dc38a26ebfada5cc0f4","9ef90549c79a4034b4a7c7b722ed822d","715ceaf94d2f4b2a8bbba675b3f04a3f","c79fb211e9ef49d69c8525f29af8669d","5f94a2ddd8d149b49a35ebaeb2ebc193","6c14e6582e224f11890520e981420ba3","1be25e6559cf45d5897a3e978f1abf8a","c74148af76744e40a47bef5d465ef05d","28cacbb2761c485dbc24e4450a8991e4","ce4e2a70b81246b0a839ac5e0454714b","ba63b2cd0c17424d99134df15530f44a","5cafceace9f94f1a945a5feeab3e5374","e1dbe9f40e0b4b4d892bfe3fecffed77","2b5948b1910248d0822275ec4a3434e6","295ac2009ec14515aec131ccaf140516","f040201763ed4ebea128af103f6a2fad","6b9282d835b948f0b7bef954a29b40b6","07aa70453c434708bef65b9133e436dd","1a1b37d40f684517b54fbe59b3e5002f","3a6992e6078540c8a425497381a5b959","8e44d04b41b149099418d1def25e0857","bec93a1d2ed840f89f5d76dd677e4983","c6b41230b7564df2b09c9e0259541b95","37cd6765556b4df9b6aecb6777756262","c8d3f11c8bab4bb587861087fa15cb77","2b2a415acde3491489facc63b12bb021","70d7502056e04d29abb9bad555318507","9dc93bf59aa14dd7bcc4d1fcd8c6fac8","9fecd5777d86450b95ed15e20f32c889","b6b72f64afb44c78b7e4e4fc5e33efd2","be9a05b8f0d74abaa2aa98e773889742","8e18b04b3ff44d5b964925b8f03ea802","041ae9d4d48a4cbdbf242b6206046d09","dd16fa59ff514f4c8c5982d5c08e7647","2f19bf5184d449d3825686ec821c33b8","fb96f7d4cce0461eb12000ae3ec29876","fdbabb52fcb14310bbb81afe9c301acb"]},"executionInfo":{"elapsed":29447,"status":"ok","timestamp":1756473337029,"user":{"displayName":"Vishal Jaiswal","userId":"13494830087982063843"},"user_tz":-330},"id":"MAXLLZPKiF90","outputId":"1dffd196-0f46-4af5-d5b1-ca3ad2ab791c"},"outputs":[{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth 2025.8.10: Fast Llama patching. Transformers: 4.55.4.\n","   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.4.0\n","\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]\n"," \"-____-\"     Free license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/1.10G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8debbbac99d4c52b010dfa0500ba874"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/234 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"613ee6146cb24bce831c5bf93ecaa5da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f94a2ddd8d149b49a35ebaeb2ebc193"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f040201763ed4ebea128af103f6a2fad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70d7502056e04d29abb9bad555318507"}},"metadata":{}}],"source":["max_seq_length = 2048\n","dtype = None\n","load_in_4bit = True\n","\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = \"unsloth/Llama-3.2-1B-Instruct\",\n","    max_seq_length = max_seq_length,\n","    dtype = dtype,\n","    load_in_4bit = load_in_4bit,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8892,"status":"ok","timestamp":1756473345926,"user":{"displayName":"Vishal Jaiswal","userId":"13494830087982063843"},"user_tz":-330},"id":"Pty40xamiyc3","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0e568ae2-ae8d-48d4-d77c-2275b8742bd0"},"outputs":[{"output_type":"stream","name":"stderr","text":["Unsloth 2025.8.10 patched 16 layers with 16 QKV layers, 16 O layers and 16 MLP layers.\n"]}],"source":["model = FastLanguageModel.get_peft_model(\n","    model,\n","    r = 16,\n","    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n","    lora_alpha = 16,\n","    lora_dropout = 0,\n","    bias = \"none\",\n","    use_gradient_checkpointing = \"unsloth\",\n","    random_state = 3407,\n","    use_rslora = False,\n","    loftq_config = None,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pom5FlR4jDrz","executionInfo":{"status":"ok","timestamp":1756699424459,"user_tz":-330,"elapsed":11596,"user":{"displayName":"Vishal Jaiswal","userId":"13494830087982063843"}},"colab":{"base_uri":"https://localhost:8080/","height":237,"referenced_widgets":["b239cc759637457d9f7ec4c1649e7af5","4c785a35ae7d4735bf9e6218104126b8","fe3a3c23656e4a4fa345b935c37cfac9","c5d5ff97fe4f414f9f7b4d441f0c3b0d","3439d9a5557246bf9963c62faa90e3af","0eb07dded5ab40038d7dc57682e2bd31","7d8deb50148b4860bb24267af82570b0","20841cf5eebf4af1adbf04065ef911f1","03fbfe42f95542bba8226ec161a6d5f2","ef53c0e050ea4c57883cff154584baf3","efde44c185164df6895aa56d2331119a","1147e41bc4574ff984ae915545cfbc12","96b95db44be244fc9cb467d7bd076518","994e17c52bc8452e9428115ae1c9d264","ea29be0abb554432a79cd37f940dbaee","06920fe0475d44fbae76cf0e9e886b5e","be4bada6a0fc4ec583bf383fc9eef8d7","3d727f36e1af47738f3a755fe824e850","0e1b08f02dd84d049fa2a41185cdcfc3","efb3971247014fffb52f84826fdd58db","7e86ef71d5254558a7d73341cedff9a6","6fa5cdef86c6486c846cff56131f53d2","fde001b7adcc41e5a1efe7e0782847a5","dfc15284d03d4b709a28ec960a30f3e9","6ea383f378084906bac5bb76d30c48f9","895e24ddd86e4874a1394fa4e4a4a114","65f0083673b748e2b46e781f0a9221b3","6c0b654bf04346559a18cb03b58615e7","d8b7c106355042afa85854c6c092d06a","55d83dac6f474f7f90d86b579bd4c873","b80ea48c7df443cbb8aa5f07c167d875","82ecc9f784aa4a88a105d2843878b9cc","4c343188f1aa4d9e8170501fc9dc1afc"]},"outputId":"10d134c8-0651-4d3d-b6b1-acac806d57c5"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["README.md:   0%|          | 0.00/863 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b239cc759637457d9f7ec4c1649e7af5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["dialogues.parquet:   0%|          | 0.00/142M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1147e41bc4574ff984ae915545cfbc12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split:   0%|          | 0/256916 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fde001b7adcc41e5a1efe7e0782847a5"}},"metadata":{}}],"source":["from datasets import load_dataset\n","\n","dataset = load_dataset(\"ruslanmv/ai-medical-chatbot\", split=\"train\")\n"]},{"cell_type":"code","source":["dataset[10015:10016]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zNm6v_9OlBGs","executionInfo":{"status":"ok","timestamp":1756699433729,"user_tz":-330,"elapsed":10,"user":{"displayName":"Vishal Jaiswal","userId":"13494830087982063843"}},"outputId":"e0c525ae-0175-45aa-ca0f-7d327362db5c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'Description': ['Q. Do vitamin B12 shots cause derealization symptoms?'],\n"," 'Patient': ['Hi doctor, I have been suffering from the derealization symptoms for the past 5 years. I believe they were caused by B12 shots I was taking to treat autism. After my brain scan I got to know that my inhibition was too high. I do not find any safety net to keep my mind from deconstructing things. A\\xa0part of me have a dislike for anything involving neuroplasticity. There are too much dichromatic thinking and lack of magical thinking. Currently, I am on Adderall and Prozac.'],\n"," 'Doctor': ['Hi. I read your query and understand your concerns. I am sorry to know that you are suffering with multiple problems related to thinking and inhibition. Before saying anything I must assure you that vitamin B12 is not known to cause any of the mentioned symptoms and we need to find out the alternative reason for causation of these symptoms. They can be due to autism itself or may be due to other psychopathology that has been arising due to autism. It is also possible that you are excessively sensitive to minor changes in thinking process. Before we make final decision, I would request you to post follow up query with the following details. I will be glad to assist you in recovering from all kind of problems related to mental health. Revert back with the information requested above to a neurologist online -->']}"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["subset=dataset[:10000]"],"metadata":{"collapsed":true,"id":"WEpg3dniO1_Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["r1_prompt = \"\"\"You are a reflective assistant engaging in thorough, iterative reasoning, mimicking human stream-of-consciousness thinking. Your approach emphasizes exploration, self-doubt, and continuous refinement before coming up with an answer.\n","<input>\n"," QUESTION:\n"," {}\n","\n"," CONTEXT:\n"," {}\n","\n","</input>\n","\n"," ANSWER:\n"," {}\n","\"\"\"\n","EOS_TOKEN = tokenizer.eos_token\n","\n","def formatting_prompts_func(examples):\n","  Questions = examples[\"Description\"]\n","  Context = examples[\"Patient\"]\n","  Answers = examples[\"Doctor\"]\n","  texts = []\n","\n","  for question, retreived_doc, answer in zip(Questions, Context, Answers):\n","    text = r1_prompt.format(question, retreived_doc, answer)+EOS_TOKEN\n","    texts.append(text)\n","\n","  return {\"text\": texts}\n","\n","from datasets import Dataset\n","\n","subset = Dataset.from_dict(subset)\n","\n","subset = subset.map(formatting_prompts_func, batched = True,)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["ebb51e6c6b4946f1973ea7e2e4e65dfe","d877e01bbe1a4d5080de07a9022a6e86","bd3a82a1dabe4e6aa44e398b87e4f999","62db874ad2e04882b55e0fb296900554","75be944f68214db0bd8f1a56ed432280","80025ac021f844d5af40ddd7e74dc5b0","6d5cbd728d0e4ef292eb068825305836","fd2da3cd55e3455f8cccc020fc15aa16","0215beafbd4e46cbb074689ecdfd0a7f","7dc059f1d3f34214ae80304b365bc372","3b787028e8a24871a9d220de8c625628"]},"id":"vr7nNur2P2DG","executionInfo":{"status":"ok","timestamp":1756473522420,"user_tz":-330,"elapsed":307,"user":{"displayName":"Vishal Jaiswal","userId":"13494830087982063843"}},"outputId":"80ff1137-b4da-4ef4-8692-736e4c5cec69"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebb51e6c6b4946f1973ea7e2e4e65dfe"}},"metadata":{}}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive',force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AaIhSQez0d5F","executionInfo":{"status":"ok","timestamp":1756565503595,"user_tz":-330,"elapsed":24833,"user":{"displayName":"Vishal Jaiswal","userId":"13494830087982063843"}},"outputId":"ec77aa80-d2b0-43be-a8f7-638a8c336f4d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["from trl import SFTTrainer\n","from transformers import TrainingArguments, DataCollatorForSeq2Seq\n","from unsloth import is_bfloat16_supported\n","\n","trainer = SFTTrainer(\n","    model = model,\n","    tokenizer = tokenizer,\n","    train_dataset = subset,\n","    dataset_text_field = \"text\",\n","    max_seq_length = max_seq_length,\n","    dataset_num_proc = 2,\n","    packing = False,\n","    args = TrainingArguments(\n","        per_device_train_batch_size = 2,\n","        gradient_accumulation_steps = 8,\n","        warmup_steps = 50,\n","        max_steps = 1000,\n","        learning_rate = 2e-4,\n","        fp16 = not is_bfloat16_supported(),\n","        bf16 = is_bfloat16_supported(),\n","        logging_steps = 20,\n","        save_steps = 300,\n","        save_total_limit = 2,\n","        optim = \"adamw_8bit\",\n","        weight_decay = 0.01,\n","        lr_scheduler_type = \"cosine\",\n","        seed = 3407,\n","        output_dir = \"outputs\",\n","        report_to = \"none\",\n","    ),\n",")"],"metadata":{"id":"h3ghcS920fgM","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["01f161eecc0245039877ffc396071c41","81b85816f3f24765b1a6ee25e9ffd89b","b2b94000fc5d41ec873f3964f1527115","b80c18f765ab4a2ebdb840680ee8c8a1","4a48c5c9bca846c181fed2ef5557f7bc","fd126621c8c442e6b05a50e2e89e4a0a","7340e3faa44b4feba9c579a38eee33bd","260ba212893b4e50bd714d898a8fa5a9","001405c3cd00416db520439b74f9800d","7cfa9c6b3891496a92e699d732663ca6","1059e03beb5a4f26ba4be30ebf7fd1ee"]},"executionInfo":{"status":"ok","timestamp":1756033980806,"user_tz":-330,"elapsed":9035,"user":{"displayName":"Vishal Jaiswal","userId":"13494830087982063843"}},"outputId":"9711ac13-d89d-4b03-d4fb-ca41f320e608"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Unsloth: Tokenizing [\"text\"]:   0%|          | 0/10000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01f161eecc0245039877ffc396071c41"}},"metadata":{}}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"pBqBClRjsvO9","outputId":"b7c00280-2542-4105-97f0-1bb341e7b0f0","executionInfo":{"status":"ok","timestamp":1756037208224,"user_tz":-330,"elapsed":3209109,"user":{"displayName":"Vishal Jaiswal","userId":"13494830087982063843"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n","   \\\\   /|    Num examples = 10,000 | Num Epochs = 2 | Total steps = 1,000\n","O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 8\n","\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 8 x 1) = 16\n"," \"-____-\"     Trainable parameters = 11,272,192 of 1,247,086,592 (0.90% trained)\n"]},{"output_type":"stream","name":"stdout","text":["Unsloth: Will smartly offload gradients to save VRAM!\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1000/1000 53:13, Epoch 1/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>20</td>\n","      <td>3.083300</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>2.344900</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>1.982700</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>1.505000</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>1.526900</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>1.281100</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>1.491100</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>1.405200</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>1.234400</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>1.254800</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>1.272600</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>1.344900</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>1.224300</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>1.362800</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>1.316600</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>1.423900</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>1.261600</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>1.410200</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>1.285900</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>1.432500</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>1.308500</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>1.256800</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>1.282400</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>1.213800</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>1.295800</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>1.237400</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>1.293300</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>1.333800</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>1.226500</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>1.333900</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>1.267700</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>1.287900</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>1.307200</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>1.261600</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>1.229000</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>1.219500</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>1.236600</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>1.241900</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>1.221400</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>1.316100</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>1.309800</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>1.225000</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>1.226900</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>1.187300</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>1.157200</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>1.225400</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>1.350400</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>1.177700</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>1.264700</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>1.345000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}],"source":["trainer_stats = trainer.train()"]},{"cell_type":"code","source":["!zip -r llama_finetune_outputs.zip /content/outputs\n","from google.colab import files\n","files.download(\"llama_finetune_outputs.zip\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":538},"id":"VJ1jDJKd-isk","executionInfo":{"status":"ok","timestamp":1756038185452,"user_tz":-330,"elapsed":11109,"user":{"displayName":"Vishal Jaiswal","userId":"13494830087982063843"}},"outputId":"67f01a4c-58eb-47ac-f7ce-706f43ea6a01","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: content/outputs/ (stored 0%)\n","  adding: content/outputs/checkpoint-1000/ (stored 0%)\n","  adding: content/outputs/checkpoint-1000/tokenizer.json (deflated 85%)\n","  adding: content/outputs/checkpoint-1000/training_args.bin (deflated 53%)\n","  adding: content/outputs/checkpoint-1000/rng_state.pth (deflated 26%)\n","  adding: content/outputs/checkpoint-1000/adapter_model.safetensors (deflated 7%)\n","  adding: content/outputs/checkpoint-1000/trainer_state.json (deflated 76%)\n","  adding: content/outputs/checkpoint-1000/README.md (deflated 65%)\n","  adding: content/outputs/checkpoint-1000/chat_template.jinja (deflated 71%)\n","  adding: content/outputs/checkpoint-1000/special_tokens_map.json (deflated 71%)\n","  adding: content/outputs/checkpoint-1000/adapter_config.json (deflated 57%)\n","  adding: content/outputs/checkpoint-1000/scaler.pt (deflated 64%)\n","  adding: content/outputs/checkpoint-1000/scheduler.pt (deflated 62%)\n","  adding: content/outputs/checkpoint-1000/optimizer.pt (deflated 11%)\n","  adding: content/outputs/checkpoint-1000/tokenizer_config.json (deflated 96%)\n","  adding: content/outputs/README.md (deflated 44%)\n","  adding: content/outputs/checkpoint-900/ (stored 0%)\n","  adding: content/outputs/checkpoint-900/tokenizer.json (deflated 85%)\n","  adding: content/outputs/checkpoint-900/training_args.bin (deflated 53%)\n","  adding: content/outputs/checkpoint-900/rng_state.pth (deflated 26%)\n","  adding: content/outputs/checkpoint-900/adapter_model.safetensors (deflated 7%)\n","  adding: content/outputs/checkpoint-900/trainer_state.json (deflated 76%)\n","  adding: content/outputs/checkpoint-900/README.md (deflated 65%)\n","  adding: content/outputs/checkpoint-900/chat_template.jinja (deflated 71%)\n","  adding: content/outputs/checkpoint-900/special_tokens_map.json (deflated 71%)\n","  adding: content/outputs/checkpoint-900/adapter_config.json (deflated 57%)\n","  adding: content/outputs/checkpoint-900/scaler.pt (deflated 64%)\n","  adding: content/outputs/checkpoint-900/scheduler.pt (deflated 61%)\n","  adding: content/outputs/checkpoint-900/optimizer.pt (deflated 11%)\n","  adding: content/outputs/checkpoint-900/tokenizer_config.json (deflated 96%)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_2f155a0c-d454-44ea-a8fe-a2ea2d1385f7\", \"llama_finetune_outputs.zip\", 130015391)"]},"metadata":{}}]},{"cell_type":"code","source":["from trl import SFTTrainer\n","from transformers import TrainingArguments, DataCollatorForSeq2Seq\n","from unsloth import is_bfloat16_supported\n","\n","\n","trainer = SFTTrainer(\n","    model=model,\n","    tokenizer=tokenizer,\n","    train_dataset=subset,\n","    dataset_text_field=\"text\",\n","    max_seq_length=max_seq_length,\n","    dataset_num_proc=2,\n","    packing=False,\n","    args=TrainingArguments(\n","        per_device_train_batch_size=2,\n","        gradient_accumulation_steps=8,\n","        warmup_steps=10,\n","        max_steps=2050,\n","        learning_rate=1e-4,\n","        fp16=not is_bfloat16_supported(),\n","        bf16=is_bfloat16_supported(),\n","        logging_steps=20,\n","        # save_steps=300,\n","        save_total_limit=2,\n","        optim=\"adamw_8bit\",\n","        weight_decay=0.01,\n","        lr_scheduler_type=\"cosine\",\n","        seed=3407,\n","        output_dir=\"/content/drive/MyDrive/llama_models/gguf\",\n","        report_to=\"none\",\n","    )\n",")\n","\n","\n","trainer_stats =trainer.train(resume_from_checkpoint=\"/content/drive/MyDrive/llama_models/content/outputs/checkpoint-2000\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":309,"referenced_widgets":["1b150cb9df4549009e69fbd61cec07e0","45c6af373f1145ba9a15b24d3de1c57a","8acf764da675428ba3613b933277e2b1","921ca7c3dac045dfb2f531d095976295","6fad782683354a1eb31cdaf3beabdedc","e2363958d0854fee94f0285d48836180","7f69322276984970910576f9c970cdb6","6f5b66c042714ef3b9cc41bfe867f28a","f6bbe07178164c18a2107fdfddd001d5","cb35e536d5634b2398d89a66230a7632","744aa692c00e42a8b0298b67b89a03f8"]},"id":"86OD9zVEC_cu","outputId":"f8849170-b5e1-4d82-c1e9-8d4e22f92ebc","executionInfo":{"status":"ok","timestamp":1756473831070,"user_tz":-330,"elapsed":219848,"user":{"displayName":"Vishal Jaiswal","userId":"13494830087982063843"}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Unsloth: Tokenizing [\"text\"] (num_proc=6):   0%|          | 0/10000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b150cb9df4549009e69fbd61cec07e0"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n","   \\\\   /|    Num examples = 10,000 | Num Epochs = 4 | Total steps = 2,050\n","O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 8\n","\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 8 x 1) = 16\n"," \"-____-\"     Trainable parameters = 11,272,192 of 1,247,086,592 (0.90% trained)\n","Warning: The following arguments do not match the ones in the `trainer_state.json` within the checkpoint directory: \n","\tsave_steps: 500 (from args) != 300 (from trainer_state.json)\n"]},{"output_type":"stream","name":"stdout","text":["Unsloth: Will smartly offload gradients to save VRAM!\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2050' max='2050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2050/2050 02:40, Epoch 3/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>2020</td>\n","      <td>1.354900</td>\n","    </tr>\n","    <tr>\n","      <td>2040</td>\n","      <td>1.210400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"code","source":["trainer.save_model(\"/content/drive/MyDrive/llama_models/content/outputs/final_model\")\n","tokenizer.save_pretrained(\"/content/drive/MyDrive/llama_models/content/outputs/final_model\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K_4RpCTXPIsW","executionInfo":{"status":"ok","timestamp":1756226166802,"user_tz":-330,"elapsed":2356,"user":{"displayName":"Vishal Jaiswal","userId":"13494830087982063843"}},"outputId":"b75d81b7-6a4a-46a8-e202-e10bd75e9d4b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('/content/drive/MyDrive/llama_models/content/outputs/final_model/tokenizer_config.json',\n"," '/content/drive/MyDrive/llama_models/content/outputs/final_model/special_tokens_map.json',\n"," '/content/drive/MyDrive/llama_models/content/outputs/final_model/chat_template.jinja',\n"," '/content/drive/MyDrive/llama_models/content/outputs/final_model/tokenizer.json')"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["!ls \"/content/drive/MyDrive/llama_models/content/outputs/final_model\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8ouaZV8bYzBF","executionInfo":{"status":"ok","timestamp":1756228697649,"user_tz":-330,"elapsed":122,"user":{"displayName":"Vishal Jaiswal","userId":"13494830087982063843"}},"outputId":"fae1f558-94d0-403c-ae0e-280c1802bf2d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["adapter_config.json\t   README.md\t\t    tokenizer.json\n","adapter_model.safetensors  special_tokens_map.json  training_args.bin\n","chat_template.jinja\t   tokenizer_config.json\n"]}]},{"cell_type":"code","source":["dataset[100012:100013]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WH0eGW_7eaBP","executionInfo":{"status":"ok","timestamp":1756565830034,"user_tz":-330,"elapsed":38,"user":{"displayName":"Vishal Jaiswal","userId":"13494830087982063843"}},"outputId":"565cdf9d-ddc4-4582-e2fa-2a9b55004b6b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'Description': ['What causes yellow bruise on the arm with pain?'],\n"," 'Patient': ['Hi, A Few days ago I found my upper left arm very painful, very randomly without injuring myself, or even banging my arm. The next day I discovered yellow bruising which has slowly turned into a rather large red/purple mark which looks like blood surfacing to the skin. This has now spread therefore is now a little bigger. This worries me as it has come out of nowhere'],\n"," 'Doctor': [\"Hello, Your symptoms are suggestive of a hematoma, which could be related to a ruptured artery or local inflammation. These are the normal stages after the hematoma and I don't think that you should worry about it. If the problem repeats, I recommend consulting with your attending physician and performing coagulation tests. Hope I have answered your query. Let me know if I can assist you further. Take care Regards, Dr Ilir Sharka, Cardiologist\"]}"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cXjZTO6BwzTR"},"outputs":[],"source":["from unsloth.chat_templates import get_chat_template\n","sys_prompt = \"\"\"You are a reflective assistant engaging in thorough, iterative reasoning, mimicking human stream-of-consciousness thinking. Your approach emphasizes exploration, self-doubt, and continuous refinement before coming up with an answer.\n","<input>\n","QUESTION:\n","{}\n","\n","CONTEXT:\n","{}\n","\n","</input>\n","ANSWER:\n","\"\"\"\n","question= \"What causes yellow bruise on the arm with pain?\"\n","context= \"Hi, A Few days ago I found my upper left arm very painful, very randomly without injuring myself, or even banging my arm. The next day I discovered yellow bruising which has slowly turned into a rather large red/purple mark which looks like blood surfacing to the skin. This has now spread therefore is now a little bigger. This worries me as it has come out of nowhere\"\n","\n","message = sys_prompt.format(question, context, \"\")\n","tokenizer = get_chat_template(\n","    tokenizer,\n","    chat_template = \"llama-3.1\",\n",")\n","FastLanguageModel.for_inference(model)\n","\n","messages = [\n","    {\"role\": \"user\", \"content\": message},\n","]\n","inputs = tokenizer.apply_chat_template(\n","    messages,\n","    tokenize = True,\n","    add_generation_prompt = True,\n","    return_tensors = \"pt\",\n",").to(\"cuda\")\n","\n","outputs = model.generate(input_ids = inputs, max_new_tokens = 1024, use_cache = True,\n","                         temperature = 1.5, min_p = 0.1)\n","response = tokenizer.batch_decode(outputs)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1756565914505,"user":{"displayName":"Vishal Jaiswal","userId":"13494830087982063843"},"user_tz":-330},"id":"5YtqW1s61rWX","outputId":"28472b5b-c2b5-4960-acd2-e5b5428a8d9a"},"outputs":[{"output_type":"stream","name":"stdout","text":["<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n","\n","Cutting Knowledge Date: December 2023\n","Today Date: 26 July 2024\n","\n","<|eot_id|><|start_header_id|>user<|end_header_id|>\n","\n","You are a reflective assistant engaging in thorough, iterative reasoning, mimicking human stream-of-consciousness thinking. Your approach emphasizes exploration, self-doubt, and continuous refinement before coming up with an answer.\n","<input>\n","QUESTION:\n","What causes yellow bruise on the arm with pain?\n","\n","CONTEXT:\n","Hi, A Few days ago I found my upper left arm very painful, very randomly without injuring myself, or even banging my arm. The next day I discovered yellow bruising which has slowly turned into a rather large red/purple mark which looks like blood surfacing to the skin. This has now spread therefore is now a little bigger. This worries me as it has come out of nowhere\n","\n","</input>\n","ANSWER:\n","<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n","\n","Hello. This may not be related to a car accident or anything that could have caused the bruise. As you have a mark of blood rising to the skin, you may be looking at an open wound, it would be best if you go and get it assessed immediately to make sure it does not bleed as a deep wound. Once the bleeding is under control, you will notice a raw area around the wound which will bleed. After about seven days the redness will subside, and you will be left with a scar. In order for you to have accurate advice I would like to have a few more details from you. For example: Do the pain and swelling vary from time to time? Are you currently on any medication? Is there any other injury to the same arm?\n","<|eot_id|>\n"]}],"source":["print(response[0])"]},{"cell_type":"code","source":["max_seq_length = 2048\n","dtype = None\n","load_in_4bit = True\n","\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = \"/content/drive/MyDrive/llama_models/content/outputs/final_model\",\n","    max_seq_length = max_seq_length,\n","    dtype = dtype,\n","    load_in_4bit = load_in_4bit,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bfzw9D3-jXER","executionInfo":{"status":"ok","timestamp":1756565542765,"user_tz":-330,"elapsed":24790,"user":{"displayName":"Vishal Jaiswal","userId":"13494830087982063843"}},"outputId":"93fe4fd6-d519-47c8-ee0f-9dfa8d3379f9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth 2025.8.10: Fast Llama patching. Transformers: 4.55.4.\n","   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.4.0\n","\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]\n"," \"-____-\"     Free license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]},{"output_type":"stream","name":"stderr","text":["Unsloth 2025.8.10 patched 16 layers with 16 QKV layers, 16 O layers and 16 MLP layers.\n"]}]},{"cell_type":"code","source":["model.save_pretrained_gguf(\n","    \"llama_finetuned\",\n","    tokenizer,\n","    quantization_method=\"q4_k_m\"\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o7Z0Wgbrj51N","executionInfo":{"status":"ok","timestamp":1756534428889,"user_tz":-330,"elapsed":455263,"user":{"displayName":"Vishal Jaiswal","userId":"13494830087982063843"}},"outputId":"c56df1a4-3912-4323-b0db-2396dc838628","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Unsloth: You have 1 CPUs. Using `safe_serialization` is 10x slower.\n","We shall switch to Pytorch saving, which might take 3 minutes and not 30 minutes.\n","To force `safe_serialization`, set it to `None` instead.\n","Unsloth: Kaggle/Colab has limited disk space. We need to delete the downloaded\n","model which will save 4-16GB of disk space, allowing you to save on Kaggle/Colab.\n","Unsloth: Will remove a cached repo with size 1.1G\n"]},{"output_type":"stream","name":"stdout","text":["Unsloth: Merging 4bit and LoRA weights to 16bit...\n","Unsloth: Will use up to 4.37 out of 12.67 RAM for saving.\n","Unsloth: Saving model... This might take 5 minutes ...\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:01<00:00, 14.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Unsloth: Saving tokenizer... Done.\n","Unsloth: Saving llama_finetuned/pytorch_model.bin...\n","Done.\n"]},{"output_type":"stream","name":"stderr","text":["Unsloth: Converting llama model. Can use fast conversion = False.\n"]},{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n","   \\\\   /|    [0] Installing llama.cpp might take 3 minutes.\n","O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits might take 3 minutes.\n","\\        /    [2] Converting GGUF 16bits to ['q4_k_m'] might take 10 minutes each.\n"," \"-____-\"     In total, you will have to wait at least 16 minutes.\n","\n","Unsloth: Installing llama.cpp. This might take 3 minutes...\n","Unsloth: CMAKE detected. Finalizing some steps for installation.\n","Unsloth: [1] Converting model at llama_finetuned into f16 GGUF format.\n","The output location will be /content/llama_finetuned/unsloth.F16.gguf\n","This might take 3 minutes...\n","INFO:hf-to-gguf:Loading model: llama_finetuned\n","INFO:hf-to-gguf:Model architecture: LlamaForCausalLM\n","INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n","INFO:hf-to-gguf:Exporting model...\n","INFO:hf-to-gguf:rope_freqs.weight,           torch.float32 --> F32, shape = {32}\n","INFO:hf-to-gguf:gguf: loading model part 'pytorch_model.bin'\n","INFO:hf-to-gguf:token_embd.weight,           torch.float16 --> F16, shape = {2048, 128256}\n","INFO:hf-to-gguf:blk.0.attn_q.weight,         torch.float16 --> F16, shape = {2048, 2048}\n","INFO:hf-to-gguf:blk.0.attn_k.weight,         torch.float16 --> F16, shape = {2048, 512}\n","INFO:hf-to-gguf:blk.0.attn_v.weight,         torch.float16 --> F16, shape = {2048, 512}\n","INFO:hf-to-gguf:blk.0.attn_output.weight,    torch.float16 --> F16, shape = {2048, 2048}\n","INFO:hf-to-gguf:blk.0.ffn_gate.weight,       torch.float16 --> F16, shape = {2048, 8192}\n","INFO:hf-to-gguf:blk.0.ffn_up.weight,         torch.float16 --> F16, shape = {2048, 8192}\n","INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 2048}\n","INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.float16 --> F32, shape = {2048}\n","INFO:hf-to-gguf:blk.0.ffn_norm.weight,       torch.float16 --> F32, shape = {2048}\n","INFO:hf-to-gguf:blk.1.attn_q.weight,         torch.float16 --> F16, shape = {2048, 2048}\n","INFO:hf-to-gguf:blk.1.attn_k.weight,         torch.float16 --> F16, shape = {2048, 512}\n","INFO:hf-to-gguf:blk.1.attn_v.weight,         torch.float16 --> F16, shape = {2048, 512}\n","INFO:hf-to-gguf:blk.1.attn_output.weight,    torch.float16 --> F16, shape = {2048, 2048}\n","INFO:hf-to-gguf:blk.1.ffn_gate.weight,       torch.float16 --> F16, shape = {2048, 8192}\n","INFO:hf-to-gguf:blk.1.ffn_up.weight,         torch.float16 --> F16, shape = {2048, 8192}\n","INFO:hf-to-gguf:blk.1.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 2048}\n","INFO:hf-to-gguf:blk.1.attn_norm.weight,      torch.float16 --> F32, shape = {2048}\n","INFO:hf-to-gguf:blk.1.ffn_norm.weight,       torch.float16 --> F32, shape = {2048}\n","INFO:hf-to-gguf:blk.2.attn_q.weight,         torch.float16 --> F16, shape = {2048, 2048}\n","INFO:hf-to-gguf:blk.2.attn_k.weight,         torch.float16 --> F16, shape = {2048, 512}\n","INFO:hf-to-gguf:blk.2.attn_v.weight,         torch.float16 --> F16, shape = {2048, 512}\n","INFO:hf-to-gguf:blk.2.attn_output.weight,    torch.float16 --> F16, shape = {2048, 2048}\n","INFO:hf-to-gguf:blk.2.ffn_gate.weight,       torch.float16 --> F16, shape = {2048, 8192}\n","INFO:hf-to-gguf:blk.2.ffn_up.weight,         torch.float16 --> F16, shape = {2048, 8192}\n","INFO:hf-to-gguf:blk.2.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 2048}\n","INFO:hf-to-gguf:blk.2.attn_norm.weight,      torch.float16 --> F32, shape = {2048}\n","INFO:hf-to-gguf:blk.2.ffn_norm.weight,       torch.float16 --> F32, shape = {2048}\n","INFO:hf-to-gguf:blk.3.attn_q.weight,         torch.float16 --> F16, shape = {2048, 2048}\n","INFO:hf-to-gguf:blk.3.attn_k.weight,         torch.float16 --> F16, shape = {2048, 512}\n","INFO:hf-to-gguf:blk.3.attn_v.weight,         torch.float16 --> F16, shape = {2048, 512}\n","INFO:hf-to-gguf:blk.3.attn_output.weight,    torch.float16 --> F16, shape = {2048, 2048}\n","INFO:hf-to-gguf:blk.3.ffn_gate.weight,       torch.float16 --> F16, shape = {2048, 8192}\n","INFO:hf-to-gguf:blk.3.ffn_up.weight,         torch.float16 --> F16, shape = {2048, 8192}\n","INFO:hf-to-gguf:blk.3.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 2048}\n","INFO:hf-to-gguf:blk.3.attn_norm.weight,      torch.float16 --> F32, shape = {2048}\n","INFO:hf-to-gguf:blk.3.ffn_norm.weight,       torch.float16 --> F32, shape = {2048}\n","INFO:hf-to-gguf:blk.4.attn_q.weight,         torch.float16 --> F16, shape = {2048, 2048}\n","INFO:hf-to-gguf:blk.4.attn_k.weight,         torch.float16 --> F16, shape = {2048, 512}\n","INFO:hf-to-gguf:blk.4.attn_v.weight,         torch.float16 --> F16, shape = {2048, 512}\n","INFO:hf-to-gguf:blk.4.attn_output.weight,    torch.float16 --> F16, shape = {2048, 2048}\n","INFO:hf-to-gguf:blk.4.ffn_gate.weight,       torch.float16 --> F16, shape = {2048, 8192}\n","INFO:hf-to-gguf:blk.4.ffn_up.weight,         torch.float16 --> F16, shape = {2048, 8192}\n","INFO:hf-to-gguf:blk.4.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 2048}\n","INFO:hf-to-gguf:blk.4.attn_norm.weight,      torch.float16 --> F32, shape = {2048}\n","INFO:hf-to-gguf:blk.4.ffn_norm.weight,       torch.float16 --> F32, shape = {2048}\n","INFO:hf-to-gguf:blk.5.attn_q.weight,         torch.float16 --> F16, shape = {2048, 2048}\n","INFO:hf-to-gguf:blk.5.attn_k.weight,         torch.float16 --> F16, shape = {2048, 512}\n","INFO:hf-to-gguf:blk.5.attn_v.weight,         torch.float16 --> F16, shape = {2048, 512}\n","INFO:hf-to-gguf:blk.5.attn_output.weight,    torch.float16 --> F16, shape = {2048, 2048}\n","INFO:hf-to-gguf:blk.5.ffn_gate.weight,       torch.float16 --> F16, shape = {2048, 8192}\n","INFO:hf-to-gguf:blk.5.ffn_up.weight,         torch.float16 --> F16, shape = {2048, 8192}\n","INFO:hf-to-gguf:blk.5.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 2048}\n","INFO:hf-to-gguf:blk.5.attn_norm.weight,      torch.float16 --> F32, shape = {2048}\n","INFO:hf-to-gguf:blk.5.ffn_norm.weight,       torch.float16 --> F32, shape = {2048}\n","INFO:hf-to-gguf:blk.6.attn_q.weight,         torch.float16 --> F16, shape = {2048, 2048}\n","INFO:hf-to-gguf:blk.6.attn_k.weight,         torch.float16 --> F16, shape = {2048, 512}\n","INFO:hf-to-gguf:blk.6.attn_v.weight,         torch.float16 --> F16, shape = {2048, 512}\n","INFO:hf-to-gguf:blk.6.attn_output.weight,    torch.float16 --> F16, shape = {2048, 2048}\n","INFO:hf-to-gguf:blk.6.ffn_gate.weight,       torch.float16 --> F16, shape = {2048, 8192}\n","INFO:hf-to-gguf:blk.6.ffn_up.weight,         torch.float16 --> F16, shape = {2048, 8192}\n","INFO:hf-to-gguf:blk.6.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 2048}\n","INFO:hf-to-gguf:blk.6.attn_norm.weight,      torch.float16 --> F32, shape = {2048}\n","INFO:hf-to-gguf:blk.6.ffn_norm.weight,       torch.float16 --> F32, shape = {2048}\n","INFO:hf-to-gguf:blk.7.attn_q.weight,         torch.float16 --> F16, shape = {2048, 2048}\n","INFO:hf-to-gguf:blk.7.attn_k.weight,         torch.float16 --> F16, shape = {2048, 512}\n","INFO:hf-to-gguf:blk.7.attn_v.weight,         torch.float16 --> F16, shape = {2048, 512}\n","INFO:hf-to-gguf:blk.7.attn_output.weight,    torch.float16 --> F16, shape = {2048, 2048}\n","INFO:hf-to-gguf:blk.7.ffn_gate.weight,       torch.float16 --> F16, shape = {2048, 8192}\n","INFO:hf-to-gguf:blk.7.ffn_up.weight,         torch.float16 --> F16, shape = {2048, 8192}\n","INFO:hf-to-gguf:blk.7.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 2048}\n","INFO:hf-to-gguf:blk.7.attn_norm.weight,      torch.float16 --> F32, shape = {2048}\n","INFO:hf-to-gguf:blk.7.ffn_norm.weight,       torch.float16 --> F32, shape = {2048}\n","INFO:hf-to-gguf:blk.8.attn_q.weight,         torch.float16 --> F16, shape = {2048, 2048}\n","INFO:hf-to-gguf:blk.8.attn_k.weight,         torch.float16 --> F16, shape = {2048, 512}\n","INFO:hf-to-gguf:blk.8.attn_v.weight,         torch.float16 --> F16, shape = {2048, 512}\n","INFO:hf-to-gguf:blk.8.attn_output.weight,    torch.float16 --> F16, shape = {2048, 2048}\n","INFO:hf-to-gguf:blk.8.ffn_gate.weight,       torch.float16 --> F16, shape = {2048, 8192}\n","INFO:hf-to-gguf:blk.8.ffn_up.weight,         torch.float16 --> F16, shape = {2048, 8192}\n","INFO:hf-to-gguf:blk.8.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 2048}\n","INFO:hf-to-gguf:blk.8.attn_norm.weight,      torch.float16 --> F32, shape = {2048}\n","INFO:hf-to-gguf:blk.8.ffn_norm.weight,       torch.float16 --> F32, shape = {2048}\n","INFO:hf-to-gguf:blk.9.attn_q.weight,         torch.float16 --> F16, shape = {2048, 2048}\n","INFO:hf-to-gguf:blk.9.attn_k.weight,         torch.float16 --> F16, shape = {2048, 512}\n","INFO:hf-to-gguf:blk.9.attn_v.weight,         torch.float16 --> F16, shape = {2048, 512}\n","INFO:hf-to-gguf:blk.9.attn_output.weight,    torch.float16 --> F16, shape = {2048, 2048}\n","INFO:hf-to-gguf:blk.9.ffn_gate.weight,       torch.float16 --> F16, shape = {2048, 8192}\n","INFO:hf-to-gguf:blk.9.ffn_up.weight,         torch.float16 --> F16, shape = {2048, 8192}\n","INFO:hf-to-gguf:blk.9.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 2048}\n","INFO:hf-to-gguf:blk.9.attn_norm.weight,      torch.float16 --> F32, shape = {2048}\n","INFO:hf-to-gguf:blk.9.ffn_norm.weight,       torch.float16 --> F32, shape = {2048}\n","INFO:hf-to-gguf:blk.10.attn_q.weight,        torch.float16 --> F16, shape = {2048, 2048}\n","INFO:hf-to-gguf:blk.10.attn_k.weight,        torch.float16 --> F16, shape = {2048, 512}\n","INFO:hf-to-gguf:blk.10.attn_v.weight,        torch.float16 --> F16, shape = {2048, 512}\n","INFO:hf-to-gguf:blk.10.attn_output.weight,   torch.float16 --> F16, shape = {2048, 2048}\n","INFO:hf-to-gguf:blk.10.ffn_gate.weight,      torch.float16 --> F16, shape = {2048, 8192}\n","INFO:hf-to-gguf:blk.10.ffn_up.weight,        torch.float16 --> F16, shape = {2048, 8192}\n","INFO:hf-to-gguf:blk.10.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 2048}\n","INFO:hf-to-gguf:blk.10.attn_norm.weight,     torch.float16 --> F32, shape = {2048}\n","INFO:hf-to-gguf:blk.10.ffn_norm.weight,      torch.float16 --> F32, shape = {2048}\n","INFO:hf-to-gguf:blk.11.attn_q.weight,        torch.float16 --> F16, shape = {2048, 2048}\n","INFO:hf-to-gguf:blk.11.attn_k.weight,        torch.float16 --> F16, shape = {2048, 512}\n","INFO:hf-to-gguf:blk.11.attn_v.weight,        torch.float16 --> F16, shape = {2048, 512}\n","INFO:hf-to-gguf:blk.11.attn_output.weight,   torch.float16 --> F16, shape = {2048, 2048}\n","INFO:hf-to-gguf:blk.11.ffn_gate.weight,      torch.float16 --> F16, shape = {2048, 8192}\n","INFO:hf-to-gguf:blk.11.ffn_up.weight,        torch.float16 --> F16, shape = {2048, 8192}\n","INFO:hf-to-gguf:blk.11.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 2048}\n","INFO:hf-to-gguf:blk.11.attn_norm.weight,     torch.float16 --> F32, shape = {2048}\n","INFO:hf-to-gguf:blk.11.ffn_norm.weight,      torch.float16 --> F32, shape = {2048}\n","INFO:hf-to-gguf:blk.12.attn_q.weight,        torch.float16 --> F16, shape = {2048, 2048}\n","INFO:hf-to-gguf:blk.12.attn_k.weight,        torch.float16 --> F16, shape = {2048, 512}\n","INFO:hf-to-gguf:blk.12.attn_v.weight,        torch.float16 --> F16, shape = {2048, 512}\n","INFO:hf-to-gguf:blk.12.attn_output.weight,   torch.float16 --> F16, shape = {2048, 2048}\n","INFO:hf-to-gguf:blk.12.ffn_gate.weight,      torch.float16 --> F16, shape = {2048, 8192}\n","INFO:hf-to-gguf:blk.12.ffn_up.weight,        torch.float16 --> F16, shape = {2048, 8192}\n","INFO:hf-to-gguf:blk.12.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 2048}\n","INFO:hf-to-gguf:blk.12.attn_norm.weight,     torch.float16 --> F32, shape = {2048}\n","INFO:hf-to-gguf:blk.12.ffn_norm.weight,      torch.float16 --> F32, shape = {2048}\n","INFO:hf-to-gguf:blk.13.attn_q.weight,        torch.float16 --> F16, shape = {2048, 2048}\n","INFO:hf-to-gguf:blk.13.attn_k.weight,        torch.float16 --> F16, shape = {2048, 512}\n","INFO:hf-to-gguf:blk.13.attn_v.weight,        torch.float16 --> F16, shape = {2048, 512}\n","INFO:hf-to-gguf:blk.13.attn_output.weight,   torch.float16 --> F16, shape = {2048, 2048}\n","INFO:hf-to-gguf:blk.13.ffn_gate.weight,      torch.float16 --> F16, shape = {2048, 8192}\n","INFO:hf-to-gguf:blk.13.ffn_up.weight,        torch.float16 --> F16, shape = {2048, 8192}\n","INFO:hf-to-gguf:blk.13.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 2048}\n","INFO:hf-to-gguf:blk.13.attn_norm.weight,     torch.float16 --> F32, shape = {2048}\n","INFO:hf-to-gguf:blk.13.ffn_norm.weight,      torch.float16 --> F32, shape = {2048}\n","INFO:hf-to-gguf:blk.14.attn_q.weight,        torch.float16 --> F16, shape = {2048, 2048}\n","INFO:hf-to-gguf:blk.14.attn_k.weight,        torch.float16 --> F16, shape = {2048, 512}\n","INFO:hf-to-gguf:blk.14.attn_v.weight,        torch.float16 --> F16, shape = {2048, 512}\n","INFO:hf-to-gguf:blk.14.attn_output.weight,   torch.float16 --> F16, shape = {2048, 2048}\n","INFO:hf-to-gguf:blk.14.ffn_gate.weight,      torch.float16 --> F16, shape = {2048, 8192}\n","INFO:hf-to-gguf:blk.14.ffn_up.weight,        torch.float16 --> F16, shape = {2048, 8192}\n","INFO:hf-to-gguf:blk.14.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 2048}\n","INFO:hf-to-gguf:blk.14.attn_norm.weight,     torch.float16 --> F32, shape = {2048}\n","INFO:hf-to-gguf:blk.14.ffn_norm.weight,      torch.float16 --> F32, shape = {2048}\n","INFO:hf-to-gguf:blk.15.attn_q.weight,        torch.float16 --> F16, shape = {2048, 2048}\n","INFO:hf-to-gguf:blk.15.attn_k.weight,        torch.float16 --> F16, shape = {2048, 512}\n","INFO:hf-to-gguf:blk.15.attn_v.weight,        torch.float16 --> F16, shape = {2048, 512}\n","INFO:hf-to-gguf:blk.15.attn_output.weight,   torch.float16 --> F16, shape = {2048, 2048}\n","INFO:hf-to-gguf:blk.15.ffn_gate.weight,      torch.float16 --> F16, shape = {2048, 8192}\n","INFO:hf-to-gguf:blk.15.ffn_up.weight,        torch.float16 --> F16, shape = {2048, 8192}\n","INFO:hf-to-gguf:blk.15.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 2048}\n","INFO:hf-to-gguf:blk.15.attn_norm.weight,     torch.float16 --> F32, shape = {2048}\n","INFO:hf-to-gguf:blk.15.ffn_norm.weight,      torch.float16 --> F32, shape = {2048}\n","INFO:hf-to-gguf:output_norm.weight,          torch.float16 --> F32, shape = {2048}\n","INFO:hf-to-gguf:Set meta model\n","INFO:hf-to-gguf:Set model parameters\n","INFO:hf-to-gguf:gguf: context length = 131072\n","INFO:hf-to-gguf:gguf: embedding length = 2048\n","INFO:hf-to-gguf:gguf: feed forward length = 8192\n","INFO:hf-to-gguf:gguf: head count = 32\n","INFO:hf-to-gguf:gguf: key-value head count = 8\n","INFO:hf-to-gguf:gguf: rope theta = 500000.0\n","INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-05\n","INFO:hf-to-gguf:gguf: file type = 1\n","INFO:hf-to-gguf:Set model quantization version\n","INFO:hf-to-gguf:Set model tokenizer\n","INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n","WARNING:gguf.vocab:Unknown separator token '<|begin_of_text|>' in TemplateProcessing<pair>\n","INFO:gguf.vocab:Adding 280147 merge(s).\n","INFO:gguf.vocab:Setting special token type bos to 128000\n","INFO:gguf.vocab:Setting special token type eos to 128009\n","INFO:gguf.vocab:Setting special token type pad to 128004\n","INFO:gguf.vocab:Setting add_bos_token to True\n","INFO:gguf.vocab:Setting add_sep_token to False\n","INFO:gguf.vocab:Setting chat_template to {{- bos_token }}\n","{%- if custom_tools is defined %}\n","    {%- set tools = custom_tools %}\n","{%- endif %}\n","{%- if not tools_in_user_message is defined %}\n","    {%- set tools_in_user_message = true %}\n","{%- endif %}\n","{%- if not date_string is defined %}\n","    {%- if strftime_now is defined %}\n","        {%- set date_string = strftime_now(\"%d %b %Y\") %}\n","    {%- else %}\n","        {%- set date_string = \"26 Jul 2024\" %}\n","    {%- endif %}\n","{%- endif %}\n","{%- if not tools is defined %}\n","    {%- set tools = none %}\n","{%- endif %}\n","\n","{#- This block extracts the system message, so we can slot it into the right place. #}\n","{%- if messages[0]['role'] == 'system' %}\n","    {%- set system_message = messages[0]['content']|trim %}\n","    {%- set messages = messages[1:] %}\n","{%- else %}\n","    {%- set system_message = \"\" %}\n","{%- endif %}\n","\n","{#- System message #}\n","{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n","{%- if tools is not none %}\n","    {{- \"Environment: ipython\\n\" }}\n","{%- endif %}\n","{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n","{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n","{%- if tools is not none and not tools_in_user_message %}\n","    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n","    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n","    {{- \"Do not use variables.\\n\\n\" }}\n","    {%- for t in tools %}\n","        {{- t | tojson(indent=4) }}\n","        {{- \"\\n\\n\" }}\n","    {%- endfor %}\n","{%- endif %}\n","{{- system_message }}\n","{{- \"<|eot_id|>\" }}\n","\n","{#- Custom tools are passed in a user message with some extra guidance #}\n","{%- if tools_in_user_message and not tools is none %}\n","    {#- Extract the first user message so we can plug it in here #}\n","    {%- if messages | length != 0 %}\n","        {%- set first_user_message = messages[0]['content']|trim %}\n","        {%- set messages = messages[1:] %}\n","    {%- else %}\n","        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n","{%- endif %}\n","    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n","    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n","    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n","    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n","    {{- \"Do not use variables.\\n\\n\" }}\n","    {%- for t in tools %}\n","        {{- t | tojson(indent=4) }}\n","        {{- \"\\n\\n\" }}\n","    {%- endfor %}\n","    {{- first_user_message + \"<|eot_id|>\"}}\n","{%- endif %}\n","\n","{%- for message in messages %}\n","    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n","        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n","    {%- elif 'tool_calls' in message %}\n","        {%- if not message.tool_calls|length == 1 %}\n","            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n","        {%- endif %}\n","        {%- set tool_call = message.tool_calls[0].function %}\n","        {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n","        {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n","        {{- '\"parameters\": ' }}\n","        {{- tool_call.arguments | tojson }}\n","        {{- \"}\" }}\n","        {{- \"<|eot_id|>\" }}\n","    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n","        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n","        {%- if message.content is mapping or message.content is iterable %}\n","            {{- message.content | tojson }}\n","        {%- else %}\n","            {{- message.content }}\n","        {%- endif %}\n","        {{- \"<|eot_id|>\" }}\n","    {%- endif %}\n","{%- endfor %}\n","{%- if add_generation_prompt %}\n","    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n","{%- endif %}\n","\n","INFO:gguf.gguf_writer:Writing the following files:\n","INFO:gguf.gguf_writer:/content/llama_finetuned/unsloth.F16.gguf: n_tensors = 147, total_size = 2.5G\n","Writing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.47G/2.47G [00:51<00:00, 48.2Mbyte/s]\n","INFO:hf-to-gguf:Model successfully exported to /content/llama_finetuned/unsloth.F16.gguf\n","Unsloth: Conversion completed! Output location: /content/llama_finetuned/unsloth.F16.gguf\n","Unsloth: [2] Converting GGUF 16bit into q4_k_m. This might take 20 minutes...\n","main: build = 6322 (ef476916)\n","main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04.2) 11.4.0 for x86_64-linux-gnu\n","main: quantizing '/content/llama_finetuned/unsloth.F16.gguf' to '/content/llama_finetuned/unsloth.Q4_K_M.gguf' as Q4_K_M using 4 threads\n","llama_model_loader: loaded meta data with 32 key-value pairs and 147 tensors from /content/llama_finetuned/unsloth.F16.gguf (version GGUF V3 (latest))\n","llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n","llama_model_loader: - kv   0:                       general.architecture str              = llama\n","llama_model_loader: - kv   1:                               general.type str              = model\n","llama_model_loader: - kv   2:                               general.name str              = Llama_Finetuned\n","llama_model_loader: - kv   3:                       general.quantized_by str              = Unsloth\n","llama_model_loader: - kv   4:                         general.size_label str              = 1.2B\n","llama_model_loader: - kv   5:                           general.repo_url str              = https://huggingface.co/unsloth\n","llama_model_loader: - kv   6:                               general.tags arr[str,2]       = [\"unsloth\", \"llama.cpp\"]\n","llama_model_loader: - kv   7:                          llama.block_count u32              = 16\n","llama_model_loader: - kv   8:                       llama.context_length u32              = 131072\n","llama_model_loader: - kv   9:                     llama.embedding_length u32              = 2048\n","llama_model_loader: - kv  10:                  llama.feed_forward_length u32              = 8192\n","llama_model_loader: - kv  11:                 llama.attention.head_count u32              = 32\n","llama_model_loader: - kv  12:              llama.attention.head_count_kv u32              = 8\n","llama_model_loader: - kv  13:                       llama.rope.freq_base f32              = 500000.000000\n","llama_model_loader: - kv  14:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n","llama_model_loader: - kv  15:                 llama.attention.key_length u32              = 64\n","llama_model_loader: - kv  16:               llama.attention.value_length u32              = 64\n","llama_model_loader: - kv  17:                          general.file_type u32              = 1\n","llama_model_loader: - kv  18:                           llama.vocab_size u32              = 128256\n","llama_model_loader: - kv  19:                 llama.rope.dimension_count u32              = 64\n","llama_model_loader: - kv  20:               general.quantization_version u32              = 2\n","llama_model_loader: - kv  21:                       tokenizer.ggml.model str              = gpt2\n","llama_model_loader: - kv  22:                         tokenizer.ggml.pre str              = llama-bpe\n","llama_model_loader: - kv  23:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n","llama_model_loader: - kv  24:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n","llama_model_loader: - kv  25:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ä  Ä \", \"Ä  Ä Ä Ä \", \"Ä Ä  Ä Ä \", \"...\n","llama_model_loader: - kv  26:                tokenizer.ggml.bos_token_id u32              = 128000\n","llama_model_loader: - kv  27:                tokenizer.ggml.eos_token_id u32              = 128009\n","llama_model_loader: - kv  28:            tokenizer.ggml.padding_token_id u32              = 128004\n","llama_model_loader: - kv  29:               tokenizer.ggml.add_bos_token bool             = true\n","llama_model_loader: - kv  30:               tokenizer.ggml.add_sep_token bool             = false\n","llama_model_loader: - kv  31:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\n","llama_model_loader: - type  f32:   34 tensors\n","llama_model_loader: - type  f16:  113 tensors\n","[   1/ 147]                   output_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n","[   2/ 147]                    rope_freqs.weight - [   32,     1,     1,     1], type =    f32, size =    0.000 MB\n","[   3/ 147]                    token_embd.weight - [ 2048, 128256,     1,     1], type =    f16, converting to q6_K .. size =   501.00 MiB ->   205.49 MiB\n","[   4/ 147]                  blk.0.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n","[   5/ 147]               blk.0.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n","[   6/ 147]             blk.0.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[   7/ 147]                  blk.0.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[   8/ 147]                  blk.0.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n","[   9/ 147]                blk.0.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n","[  10/ 147]                blk.0.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  11/ 147]                blk.0.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n","[  12/ 147]                  blk.0.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  13/ 147]                  blk.1.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n","[  14/ 147]               blk.1.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n","[  15/ 147]             blk.1.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  16/ 147]                  blk.1.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  17/ 147]                  blk.1.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n","[  18/ 147]                blk.1.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n","[  19/ 147]                blk.1.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  20/ 147]                blk.1.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n","[  21/ 147]                  blk.1.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  22/ 147]                  blk.2.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n","[  23/ 147]               blk.2.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n","[  24/ 147]             blk.2.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  25/ 147]                  blk.2.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  26/ 147]                  blk.2.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n","[  27/ 147]                blk.2.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  28/ 147]                blk.2.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  29/ 147]                blk.2.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n","[  30/ 147]                  blk.2.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  31/ 147]                  blk.3.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n","[  32/ 147]               blk.3.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n","[  33/ 147]             blk.3.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  34/ 147]                  blk.3.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  35/ 147]                  blk.3.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n","[  36/ 147]                blk.3.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  37/ 147]                blk.3.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  38/ 147]                blk.3.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n","[  39/ 147]                  blk.3.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  40/ 147]                  blk.4.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n","[  41/ 147]               blk.4.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n","[  42/ 147]             blk.4.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  43/ 147]                  blk.4.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  44/ 147]                  blk.4.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n","[  45/ 147]                blk.4.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n","[  46/ 147]                blk.4.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  47/ 147]                blk.4.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n","[  48/ 147]                  blk.4.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  49/ 147]                  blk.5.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n","[  50/ 147]               blk.5.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n","[  51/ 147]             blk.5.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  52/ 147]                  blk.5.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  53/ 147]                  blk.5.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n","[  54/ 147]                blk.5.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  55/ 147]                blk.5.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  56/ 147]                blk.5.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n","[  57/ 147]                  blk.5.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  58/ 147]                  blk.6.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n","[  59/ 147]               blk.6.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n","[  60/ 147]             blk.6.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  61/ 147]                  blk.6.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  62/ 147]                  blk.6.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n","[  63/ 147]                blk.6.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  64/ 147]                blk.6.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  65/ 147]                blk.6.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n","[  66/ 147]                  blk.6.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  67/ 147]                  blk.7.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n","[  68/ 147]               blk.7.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n","[  69/ 147]             blk.7.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  70/ 147]                  blk.7.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  71/ 147]                  blk.7.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n","[  72/ 147]                blk.7.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n","[  73/ 147]                blk.7.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  74/ 147]                blk.7.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n","[  75/ 147]                  blk.7.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  76/ 147]                  blk.8.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n","[  77/ 147]               blk.8.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n","[  78/ 147]             blk.8.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  79/ 147]                  blk.8.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  80/ 147]                  blk.8.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n","[  81/ 147]                blk.8.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  82/ 147]                blk.8.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  83/ 147]                blk.8.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n","[  84/ 147]                  blk.8.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  85/ 147]                  blk.9.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n","[  86/ 147]               blk.9.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n","[  87/ 147]             blk.9.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  88/ 147]                  blk.9.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  89/ 147]                  blk.9.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n","[  90/ 147]                blk.9.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  91/ 147]                blk.9.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  92/ 147]                blk.9.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n","[  93/ 147]                  blk.9.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  94/ 147]                 blk.10.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n","[  95/ 147]              blk.10.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n","[  96/ 147]            blk.10.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  97/ 147]                 blk.10.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  98/ 147]                 blk.10.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n","[  99/ 147]               blk.10.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n","[ 100/ 147]               blk.10.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 101/ 147]               blk.10.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n","[ 102/ 147]                 blk.10.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 103/ 147]                 blk.11.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n","[ 104/ 147]              blk.11.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n","[ 105/ 147]            blk.11.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 106/ 147]                 blk.11.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 107/ 147]                 blk.11.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n","[ 108/ 147]               blk.11.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 109/ 147]               blk.11.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 110/ 147]               blk.11.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n","[ 111/ 147]                 blk.11.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 112/ 147]                 blk.12.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n","[ 113/ 147]              blk.12.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n","[ 114/ 147]            blk.12.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 115/ 147]                 blk.12.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 116/ 147]                 blk.12.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n","[ 117/ 147]               blk.12.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 118/ 147]               blk.12.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 119/ 147]               blk.12.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n","[ 120/ 147]                 blk.12.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 121/ 147]                 blk.13.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n","[ 122/ 147]              blk.13.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n","[ 123/ 147]            blk.13.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 124/ 147]                 blk.13.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 125/ 147]                 blk.13.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n","[ 126/ 147]               blk.13.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n","[ 127/ 147]               blk.13.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 128/ 147]               blk.13.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n","[ 129/ 147]                 blk.13.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 130/ 147]                 blk.14.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n","[ 131/ 147]              blk.14.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n","[ 132/ 147]            blk.14.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 133/ 147]                 blk.14.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 134/ 147]                 blk.14.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n","[ 135/ 147]               blk.14.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n","[ 136/ 147]               blk.14.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 137/ 147]               blk.14.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n","[ 138/ 147]                 blk.14.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 139/ 147]                 blk.15.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n","[ 140/ 147]              blk.15.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n","[ 141/ 147]            blk.15.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 142/ 147]                 blk.15.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 143/ 147]                 blk.15.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n","[ 144/ 147]               blk.15.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n","[ 145/ 147]               blk.15.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 146/ 147]               blk.15.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n","[ 147/ 147]                 blk.15.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","llama_model_quantize_impl: model size  =  2357.26 MB\n","llama_model_quantize_impl: quant size  =   762.81 MB\n","\n","main: quantize time = 124588.26 ms\n","main:    total time = 124588.26 ms\n","Unsloth: Conversion completed! Output location: /content/llama_finetuned/unsloth.Q4_K_M.gguf\n"]}]},{"cell_type":"code","source":["import shutil\n","from google.colab import files\n","\n","shutil.make_archive(\"llama_finetuned\", 'zip', \"/content/llama_finetuned\")\n","files.download(\"llama_finetuned.zip\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"N4QtXOEBlWBs","executionInfo":{"status":"ok","timestamp":1756534852141,"user_tz":-330,"elapsed":412164,"user":{"displayName":"Vishal Jaiswal","userId":"13494830087982063843"}},"outputId":"b85fd1eb-84b5-4a1f-fd66-5ba7e1bb1acb"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_561cb196-110a-414d-b301-78bf776a60c6\", \"llama_finetuned.zip\", 5195672353)"]},"metadata":{}}]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPx4kW9cec8kz2Ii3cCgsMX"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"01f161eecc0245039877ffc396071c41":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_81b85816f3f24765b1a6ee25e9ffd89b","IPY_MODEL_b2b94000fc5d41ec873f3964f1527115","IPY_MODEL_b80c18f765ab4a2ebdb840680ee8c8a1"],"layout":"IPY_MODEL_4a48c5c9bca846c181fed2ef5557f7bc"}},"81b85816f3f24765b1a6ee25e9ffd89b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd126621c8c442e6b05a50e2e89e4a0a","placeholder":"â€‹","style":"IPY_MODEL_7340e3faa44b4feba9c579a38eee33bd","value":"Unsloth:â€‡Tokenizingâ€‡[&quot;text&quot;]:â€‡100%"}},"b2b94000fc5d41ec873f3964f1527115":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_260ba212893b4e50bd714d898a8fa5a9","max":10000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_001405c3cd00416db520439b74f9800d","value":10000}},"b80c18f765ab4a2ebdb840680ee8c8a1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7cfa9c6b3891496a92e699d732663ca6","placeholder":"â€‹","style":"IPY_MODEL_1059e03beb5a4f26ba4be30ebf7fd1ee","value":"â€‡10000/10000â€‡[00:08&lt;00:00,â€‡1212.19â€‡examples/s]"}},"4a48c5c9bca846c181fed2ef5557f7bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd126621c8c442e6b05a50e2e89e4a0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7340e3faa44b4feba9c579a38eee33bd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"260ba212893b4e50bd714d898a8fa5a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"001405c3cd00416db520439b74f9800d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7cfa9c6b3891496a92e699d732663ca6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1059e03beb5a4f26ba4be30ebf7fd1ee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f8debbbac99d4c52b010dfa0500ba874":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fe3c441eb73b40dfadc9e078ffc28d2e","IPY_MODEL_aad28fbe9fc24853ad98d9954228a372","IPY_MODEL_7d5f9ea80e3440aeac015a3af03092ad"],"layout":"IPY_MODEL_f7007d8b15204904882c4e7f6e353f48"}},"fe3c441eb73b40dfadc9e078ffc28d2e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_521f4aa6518343809f597a36e1fd23d0","placeholder":"â€‹","style":"IPY_MODEL_7b0b3ef4e62d4cd8adf035cf36d9b734","value":"model.safetensors:â€‡100%"}},"aad28fbe9fc24853ad98d9954228a372":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_02383d6b7a6741a68c5f7e445b31308e","max":1102370060,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1bff7981c1834c0a8a1f6392b5f62a6e","value":1102370060}},"7d5f9ea80e3440aeac015a3af03092ad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b0c78818b1e4e20a7dcc4e277b47297","placeholder":"â€‹","style":"IPY_MODEL_0aa8103b97a14d40a1f91b6549fc9d93","value":"â€‡1.10G/1.10Gâ€‡[00:16&lt;00:00,â€‡64.7MB/s]"}},"f7007d8b15204904882c4e7f6e353f48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"521f4aa6518343809f597a36e1fd23d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b0b3ef4e62d4cd8adf035cf36d9b734":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"02383d6b7a6741a68c5f7e445b31308e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1bff7981c1834c0a8a1f6392b5f62a6e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8b0c78818b1e4e20a7dcc4e277b47297":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0aa8103b97a14d40a1f91b6549fc9d93":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"613ee6146cb24bce831c5bf93ecaa5da":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2bfcd192129343f2b47e1f16f052542a","IPY_MODEL_2a983c8a9bab4ca9a12c3a333d478716","IPY_MODEL_7a557c285f8f478fb344e367ecc34f2c"],"layout":"IPY_MODEL_ab899d8966d843dab10f241d9cdffeea"}},"2bfcd192129343f2b47e1f16f052542a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b857b8af2b294f52b717ce116e30dec0","placeholder":"â€‹","style":"IPY_MODEL_cef84c1d6247454a894255fd6eefd6b2","value":"generation_config.json:â€‡100%"}},"2a983c8a9bab4ca9a12c3a333d478716":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_952f7db6d1f14dc38a26ebfada5cc0f4","max":234,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9ef90549c79a4034b4a7c7b722ed822d","value":234}},"7a557c285f8f478fb344e367ecc34f2c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_715ceaf94d2f4b2a8bbba675b3f04a3f","placeholder":"â€‹","style":"IPY_MODEL_c79fb211e9ef49d69c8525f29af8669d","value":"â€‡234/234â€‡[00:00&lt;00:00,â€‡11.4kB/s]"}},"ab899d8966d843dab10f241d9cdffeea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b857b8af2b294f52b717ce116e30dec0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cef84c1d6247454a894255fd6eefd6b2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"952f7db6d1f14dc38a26ebfada5cc0f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ef90549c79a4034b4a7c7b722ed822d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"715ceaf94d2f4b2a8bbba675b3f04a3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c79fb211e9ef49d69c8525f29af8669d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5f94a2ddd8d149b49a35ebaeb2ebc193":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6c14e6582e224f11890520e981420ba3","IPY_MODEL_1be25e6559cf45d5897a3e978f1abf8a","IPY_MODEL_c74148af76744e40a47bef5d465ef05d"],"layout":"IPY_MODEL_28cacbb2761c485dbc24e4450a8991e4"}},"6c14e6582e224f11890520e981420ba3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce4e2a70b81246b0a839ac5e0454714b","placeholder":"â€‹","style":"IPY_MODEL_ba63b2cd0c17424d99134df15530f44a","value":"tokenizer_config.json:â€‡"}},"1be25e6559cf45d5897a3e978f1abf8a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5cafceace9f94f1a945a5feeab3e5374","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e1dbe9f40e0b4b4d892bfe3fecffed77","value":1}},"c74148af76744e40a47bef5d465ef05d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b5948b1910248d0822275ec4a3434e6","placeholder":"â€‹","style":"IPY_MODEL_295ac2009ec14515aec131ccaf140516","value":"â€‡54.7k/?â€‡[00:00&lt;00:00,â€‡2.32MB/s]"}},"28cacbb2761c485dbc24e4450a8991e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce4e2a70b81246b0a839ac5e0454714b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba63b2cd0c17424d99134df15530f44a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5cafceace9f94f1a945a5feeab3e5374":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"e1dbe9f40e0b4b4d892bfe3fecffed77":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2b5948b1910248d0822275ec4a3434e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"295ac2009ec14515aec131ccaf140516":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f040201763ed4ebea128af103f6a2fad":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6b9282d835b948f0b7bef954a29b40b6","IPY_MODEL_07aa70453c434708bef65b9133e436dd","IPY_MODEL_1a1b37d40f684517b54fbe59b3e5002f"],"layout":"IPY_MODEL_3a6992e6078540c8a425497381a5b959"}},"6b9282d835b948f0b7bef954a29b40b6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e44d04b41b149099418d1def25e0857","placeholder":"â€‹","style":"IPY_MODEL_bec93a1d2ed840f89f5d76dd677e4983","value":"special_tokens_map.json:â€‡100%"}},"07aa70453c434708bef65b9133e436dd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6b41230b7564df2b09c9e0259541b95","max":454,"min":0,"orientation":"horizontal","style":"IPY_MODEL_37cd6765556b4df9b6aecb6777756262","value":454}},"1a1b37d40f684517b54fbe59b3e5002f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8d3f11c8bab4bb587861087fa15cb77","placeholder":"â€‹","style":"IPY_MODEL_2b2a415acde3491489facc63b12bb021","value":"â€‡454/454â€‡[00:00&lt;00:00,â€‡17.1kB/s]"}},"3a6992e6078540c8a425497381a5b959":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e44d04b41b149099418d1def25e0857":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bec93a1d2ed840f89f5d76dd677e4983":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c6b41230b7564df2b09c9e0259541b95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37cd6765556b4df9b6aecb6777756262":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c8d3f11c8bab4bb587861087fa15cb77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b2a415acde3491489facc63b12bb021":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"70d7502056e04d29abb9bad555318507":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9dc93bf59aa14dd7bcc4d1fcd8c6fac8","IPY_MODEL_9fecd5777d86450b95ed15e20f32c889","IPY_MODEL_b6b72f64afb44c78b7e4e4fc5e33efd2"],"layout":"IPY_MODEL_be9a05b8f0d74abaa2aa98e773889742"}},"9dc93bf59aa14dd7bcc4d1fcd8c6fac8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e18b04b3ff44d5b964925b8f03ea802","placeholder":"â€‹","style":"IPY_MODEL_041ae9d4d48a4cbdbf242b6206046d09","value":"tokenizer.json:â€‡100%"}},"9fecd5777d86450b95ed15e20f32c889":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd16fa59ff514f4c8c5982d5c08e7647","max":17209920,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2f19bf5184d449d3825686ec821c33b8","value":17209920}},"b6b72f64afb44c78b7e4e4fc5e33efd2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb96f7d4cce0461eb12000ae3ec29876","placeholder":"â€‹","style":"IPY_MODEL_fdbabb52fcb14310bbb81afe9c301acb","value":"â€‡17.2M/17.2Mâ€‡[00:00&lt;00:00,â€‡25.6MB/s]"}},"be9a05b8f0d74abaa2aa98e773889742":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e18b04b3ff44d5b964925b8f03ea802":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"041ae9d4d48a4cbdbf242b6206046d09":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dd16fa59ff514f4c8c5982d5c08e7647":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f19bf5184d449d3825686ec821c33b8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fb96f7d4cce0461eb12000ae3ec29876":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fdbabb52fcb14310bbb81afe9c301acb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ebb51e6c6b4946f1973ea7e2e4e65dfe":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d877e01bbe1a4d5080de07a9022a6e86","IPY_MODEL_bd3a82a1dabe4e6aa44e398b87e4f999","IPY_MODEL_62db874ad2e04882b55e0fb296900554"],"layout":"IPY_MODEL_75be944f68214db0bd8f1a56ed432280"}},"d877e01bbe1a4d5080de07a9022a6e86":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_80025ac021f844d5af40ddd7e74dc5b0","placeholder":"â€‹","style":"IPY_MODEL_6d5cbd728d0e4ef292eb068825305836","value":"Map:â€‡100%"}},"bd3a82a1dabe4e6aa44e398b87e4f999":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd2da3cd55e3455f8cccc020fc15aa16","max":10000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0215beafbd4e46cbb074689ecdfd0a7f","value":10000}},"62db874ad2e04882b55e0fb296900554":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7dc059f1d3f34214ae80304b365bc372","placeholder":"â€‹","style":"IPY_MODEL_3b787028e8a24871a9d220de8c625628","value":"â€‡10000/10000â€‡[00:00&lt;00:00,â€‡45481.92â€‡examples/s]"}},"75be944f68214db0bd8f1a56ed432280":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80025ac021f844d5af40ddd7e74dc5b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d5cbd728d0e4ef292eb068825305836":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd2da3cd55e3455f8cccc020fc15aa16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0215beafbd4e46cbb074689ecdfd0a7f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7dc059f1d3f34214ae80304b365bc372":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b787028e8a24871a9d220de8c625628":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1b150cb9df4549009e69fbd61cec07e0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_45c6af373f1145ba9a15b24d3de1c57a","IPY_MODEL_8acf764da675428ba3613b933277e2b1","IPY_MODEL_921ca7c3dac045dfb2f531d095976295"],"layout":"IPY_MODEL_6fad782683354a1eb31cdaf3beabdedc"}},"45c6af373f1145ba9a15b24d3de1c57a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2363958d0854fee94f0285d48836180","placeholder":"â€‹","style":"IPY_MODEL_7f69322276984970910576f9c970cdb6","value":"Unsloth:â€‡Tokenizingâ€‡[&quot;text&quot;]â€‡(num_proc=6):â€‡100%"}},"8acf764da675428ba3613b933277e2b1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f5b66c042714ef3b9cc41bfe867f28a","max":10000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f6bbe07178164c18a2107fdfddd001d5","value":10000}},"921ca7c3dac045dfb2f531d095976295":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb35e536d5634b2398d89a66230a7632","placeholder":"â€‹","style":"IPY_MODEL_744aa692c00e42a8b0298b67b89a03f8","value":"â€‡10000/10000â€‡[00:22&lt;00:00,â€‡939.02â€‡examples/s]"}},"6fad782683354a1eb31cdaf3beabdedc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2363958d0854fee94f0285d48836180":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f69322276984970910576f9c970cdb6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6f5b66c042714ef3b9cc41bfe867f28a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6bbe07178164c18a2107fdfddd001d5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cb35e536d5634b2398d89a66230a7632":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"744aa692c00e42a8b0298b67b89a03f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b239cc759637457d9f7ec4c1649e7af5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4c785a35ae7d4735bf9e6218104126b8","IPY_MODEL_fe3a3c23656e4a4fa345b935c37cfac9","IPY_MODEL_c5d5ff97fe4f414f9f7b4d441f0c3b0d"],"layout":"IPY_MODEL_3439d9a5557246bf9963c62faa90e3af"}},"4c785a35ae7d4735bf9e6218104126b8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0eb07dded5ab40038d7dc57682e2bd31","placeholder":"â€‹","style":"IPY_MODEL_7d8deb50148b4860bb24267af82570b0","value":"README.md:â€‡100%"}},"fe3a3c23656e4a4fa345b935c37cfac9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_20841cf5eebf4af1adbf04065ef911f1","max":863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_03fbfe42f95542bba8226ec161a6d5f2","value":863}},"c5d5ff97fe4f414f9f7b4d441f0c3b0d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef53c0e050ea4c57883cff154584baf3","placeholder":"â€‹","style":"IPY_MODEL_efde44c185164df6895aa56d2331119a","value":"â€‡863/863â€‡[00:00&lt;00:00,â€‡22.4kB/s]"}},"3439d9a5557246bf9963c62faa90e3af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0eb07dded5ab40038d7dc57682e2bd31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d8deb50148b4860bb24267af82570b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"20841cf5eebf4af1adbf04065ef911f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03fbfe42f95542bba8226ec161a6d5f2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ef53c0e050ea4c57883cff154584baf3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efde44c185164df6895aa56d2331119a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1147e41bc4574ff984ae915545cfbc12":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_96b95db44be244fc9cb467d7bd076518","IPY_MODEL_994e17c52bc8452e9428115ae1c9d264","IPY_MODEL_ea29be0abb554432a79cd37f940dbaee"],"layout":"IPY_MODEL_06920fe0475d44fbae76cf0e9e886b5e"}},"96b95db44be244fc9cb467d7bd076518":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be4bada6a0fc4ec583bf383fc9eef8d7","placeholder":"â€‹","style":"IPY_MODEL_3d727f36e1af47738f3a755fe824e850","value":"dialogues.parquet:â€‡100%"}},"994e17c52bc8452e9428115ae1c9d264":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e1b08f02dd84d049fa2a41185cdcfc3","max":141665910,"min":0,"orientation":"horizontal","style":"IPY_MODEL_efb3971247014fffb52f84826fdd58db","value":141665910}},"ea29be0abb554432a79cd37f940dbaee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e86ef71d5254558a7d73341cedff9a6","placeholder":"â€‹","style":"IPY_MODEL_6fa5cdef86c6486c846cff56131f53d2","value":"â€‡142M/142Mâ€‡[00:01&lt;00:00,â€‡98.4MB/s]"}},"06920fe0475d44fbae76cf0e9e886b5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be4bada6a0fc4ec583bf383fc9eef8d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d727f36e1af47738f3a755fe824e850":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0e1b08f02dd84d049fa2a41185cdcfc3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efb3971247014fffb52f84826fdd58db":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7e86ef71d5254558a7d73341cedff9a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6fa5cdef86c6486c846cff56131f53d2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fde001b7adcc41e5a1efe7e0782847a5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dfc15284d03d4b709a28ec960a30f3e9","IPY_MODEL_6ea383f378084906bac5bb76d30c48f9","IPY_MODEL_895e24ddd86e4874a1394fa4e4a4a114"],"layout":"IPY_MODEL_65f0083673b748e2b46e781f0a9221b3"}},"dfc15284d03d4b709a28ec960a30f3e9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c0b654bf04346559a18cb03b58615e7","placeholder":"â€‹","style":"IPY_MODEL_d8b7c106355042afa85854c6c092d06a","value":"Generatingâ€‡trainâ€‡split:â€‡100%"}},"6ea383f378084906bac5bb76d30c48f9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_55d83dac6f474f7f90d86b579bd4c873","max":256916,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b80ea48c7df443cbb8aa5f07c167d875","value":256916}},"895e24ddd86e4874a1394fa4e4a4a114":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_82ecc9f784aa4a88a105d2843878b9cc","placeholder":"â€‹","style":"IPY_MODEL_4c343188f1aa4d9e8170501fc9dc1afc","value":"â€‡256916/256916â€‡[00:02&lt;00:00,â€‡130168.01â€‡examples/s]"}},"65f0083673b748e2b46e781f0a9221b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c0b654bf04346559a18cb03b58615e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8b7c106355042afa85854c6c092d06a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"55d83dac6f474f7f90d86b579bd4c873":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b80ea48c7df443cbb8aa5f07c167d875":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"82ecc9f784aa4a88a105d2843878b9cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c343188f1aa4d9e8170501fc9dc1afc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}